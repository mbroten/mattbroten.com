<h2 class="centered">An Analysis of John Searle's Arguments Against Strong AI in "<a href="http://cogprints.org/7150/"><span class="nowrap">Minds, Brains, and Programs</span></a>"</h2>
<h3 class="centered">Author: <a href="http://mattbroten.com">Matt Broten</a></h3>
<h3 class="centered">Completed for Philosophy 4615 - Minds, Bodies, and Machines at the <a href="http://umn.edu"><span class="nowrap">University of Minnesota</span></a></h3>


<p>
In "Minds, Brains, and Programs" John Searle presents an argument against strong AI (artificial intelligence). According to Searle the stance taken by strong AI is captured by two claims. First, a computer given a program that is composed of the right set of instructions has actual cognitive states; thus, such a system is a mind with the ability to understand. Second, the program itself offers an explanation of human cognition. In contrast, weak AI, as defined by Searle, takes the position that a computer running a particular program does not have cognitive states but instead can be used as a tool to simulate and test explanations of mental processes. As a concrete example of a program that could be said to exhibit strong AI, Searle presents the work of Roger Schank. The program developed by Schank takes as input a story and questions about the story. Using information about the world available to the program, which is contained within a representation referred to as a script, the program is able to answer questions about the story in a way that could be said to demonstrate human understanding.
</p>

<p>
Searle begins his argument against the claims of strong AI by presenting the following thought experiment. Searle himself is first put inside a room. Once inside the room he has no access to the outside world except via a slot in which paper can be pushed through. Through this slot he is given three collections of Chinese writing along with a book of rules written in English. Searle is not able to understand the Chinese writing; to him the Chinese characters have as much meaning as a bunch of random scribbles. He is however able to read the rules in the book because he is fluent in English. The rules allow him to associate Chinese characters between each collection of Chinese writing. He is directed by the rules to write down certain Chinese characters in response to the given collections of Chinese writing. While doing this, he does not understand what he is writing down. All he is doing is matching symbols based on their appearance. Once he is finished, he passes the response through the slot. Unknown to Searle one collection of Chinese writing corresponds to a script, another corresponds to a story, and another corresponds to questions about the story. Similarly, Searle does not know that the response he passes back through the slot corresponds to answers to the questions. The book full of rules written in English then becomes Schank's program. To an observer outside the room the answers can not be differentiated from answers that a person fluent in Chinese would give. Now Searle is given in English a story and questions to this story. In this case he understands the story and the questions, and writes down appropriate answers in English. He passes the answers through the slot, and again to an outside observer the answers can not be distinguished from answers that a person fluent in English would give. To the outside observer the responses he gave to the Chinese questions are equivalent to the responses he gave to the English questions in the following sense: neither response can be told apart from answers given by native speakers of the language the responses were written in. 
</p>

<p>
After Searle presents the thought experiment, he goes on to argue against the first claim of strong AI: a computer given the proper program has mental states such as understanding. In Searle's thought experiment he takes the place of the computer and manually runs Schank's program. Searle argues that although he is able to respond with answers that cannot be differentiated from those of a fluent Chinese speaker when given the script, story, and questions, he does not understand Chinese and thus does not exhibit any understanding during the process of answering questions. He is the computer in this situation and understands nothing. A computer does not have anything that he lacks which would allow it to understand. Thus, Searle argues, an actual computer running Schank's program does not understand anything. 
</p>

<p>
Searle then addresses the second claim of strong AI: a program such as Schank's offers an explanation of understanding. Searle argues that no explanation of understanding is offered by a computer running a program because as in his though experiment a human can run a program manually and not understand anything. Searle then turns to address whether such a program is even to be considered a component of understanding. Searle mentions that supporters of strong AI say that in the case of understanding English, symbol manipulation of the same type (as in formulating Chinese responses in the thought experiment) is being done but a greater amount. Searle argues that although this is a possibility, his thought experiment suggests that the program adds nothing to his understanding, and there is no reason to suspect a program has anything to do with his understanding of the English questions. 
</p>

<p>
Searle's argument differs in an important way from classical arguments against strong AI. Classical arguments against AI all try to point something that a human has but a machine lacks. Such arguments take the following form: a human has x which is required for intelligence; a computer does not have x; therefore, a computer cannot be intelligent. Searle instead points to something that humans and computers both have to argue against AI, namely the ability to run a program. Searle's argument takes the following form: a human and a computer can do x; when a human does x, the human does not understand; thus when a computer does x, the computer does not understand since the computer has nothing more than a human (that would allow it to understand). Searle of course extends this reasoning to say that x, the ability to run a program, is not sufficient for understanding. 
</p>

<p>
In pursing a critical discussion of Searle's argument against strong AI, a look at some of the replies to his argument and his response back to those replies is warranted. The first reply presented by Searle is referred to by him as the systems reply.
</p>

<p>
The systems reply points out that Searle (the person in the room) is only a single component of a system, which consists of the room and everything in it including the collections of Chinese writing and the book of English rules; while he doesn't understand Chinese, the system does. Searle responds to this reply by offering that he could memorize all of the Chinese writing and the book of rules and then do all of the symbol manipulation in his head. He claims that this way the system would be a part of him, and since he would still not understand Chinese, the system would not understand Chinese either. Searle notes that some would be opposed to this notion. According to Searle, those opposed would say that there would be two different subsystems in his head, one for English and one for Chinese. In explaining the opposing view, Searle says that the subsystem for Chinese would understand Chinese, but in a different way than a native Chinese speaker understands Chinese since the subsystem would only be doing symbol manipulation without knowing what the symbols actually refer to in the world. Searle goes on to say that this is exactly the problem; both subsystems could pass the Turing Test, but only the English subsystem can be said to possess understanding on a semantic level. Searle continues by saying that if a system is judged as possessing mental states based only on the observation that it responds to certain input with certain output and does so using a program, then many systems that do not have mental states can be said to have mental states.  
</p>

<p>
The next reply presented by Searle is referred to by him as the robot reply. The robot reply suggests that a robot instead of a computer running Schank's program be discussed. The robot would house a computer that controls the robot's interaction with the world. As input the computer would take in signals from robot's external sensors (e.g. a video camera for vision) and as output the computer would send out signals to the motors that allow the robot to physically move around. In contrast to the computer running Schank's program, this system could be said to have actual cognitive states such as understanding. Searle responds by saying that his thought experiment still applies in this case. Searle could again take the place of the computer inside the robot. Just as in the room Chinese writing is delivered to Searle and he follows rules written in English to come up with Chinese writing as responses. This time the writing coming to Searle corresponds to signals being sent by the external sensors, and the responses given by Searle correspond to signals being sent to the motors that allow the robot to move around. Again as Searle does symbol manipulation he does not understand what the writing means; he has no idea what the input or output refers to. Searle argues that in taking the place of the computer he has no understanding. Similarly, he contends that the robot interacts with the world as a result of the program run by the computer and it does not have any understanding.
</p>

<p>
Another reply presented by Searle is referred to him as the combination reply. This reply is a combination of the system reply and the robot reply. Note that the combination reply in "Minds, Brains, and Programs" actually includes another reply referred to by Searle as the brain simulator reply. This reply and Searle's response to the reply were not presented because the reply offers a hardware architecture which mirrors the brain in place of a standard computer architecture; according to the claims of strong AI as set out by Searle, we are concerned with having the right program not the hardware on which the program runs. The combination reply presents a robot that interacts with the world and exhibits behavior that cannot be told apart from the behavior of a human. Searle responds by admitting that in this case, there would be no reason not to assume that the system was able to understand and possess other mental states. He goes on to say that if we knew how the system really worked, that its actions were the result of a program, we would no longer say that it was able to understand. 
</p>

<p>
In light of the system reply and Searle's response to that reply, a few points can be made about Searle's argument against strong AI. Note that the use of the phrase "Searle's argument" in the following refers to Searle's argument against strong AI, namely his thought experiment. Searle does not show that the system as a whole is unable to understand. In Searle's argument the system is said to not understand Chinese because none of the components of the system understands Chinese implying that for the system to understand Chinese there must be a component of the system that understands Chinese. This implies that understanding in a system cannot emerge from the sum of the components which on their own are unable to understand. With this line of reasoning the human brain would need a component which understands and that component would require a subcomponent that understands and so on. We know that this would be impossible since any one subatomic particle could not be attributed understanding. Thus, Searle's argument cannot show the system as a whole does not understand on this reasoning. In contrast, Searle's thought experiment implies that the system as a whole is able to understand in some sense of the word because outside observers are fooled in thinking it does. However, Searle's argument does indicate that there is something more to his understanding of English as compared to the system's understanding of Chinese. He knows what the symbols in English mean in terms of the real world. The system understands Chinese in that it is able to respond correctly to the input it is given, but it has no idea what the symbols mean in relation to the world. Searle's argument also shows that a system capable of passing the Turing test does not have to possess understanding on a semantic level. Such a system can demonstrate understanding to the outside observer while operating on a syntactic level. Searle's argument thus suggests a problem with the original formulation of the Turing Test. 
</p>

<p>
The robot reply and Searle's response to that reply confront an important issue that was previously touched on. The robot reply gives the room the ability to interact with the world. Now the system can attach meaning to its inputs. Searle shows that this is still not enough for semantic understanding. The computer inside the robot does not understand the symbols it is manipulating on a semantic level. The robot, the shell in which the computer resides, does not understand on this level either because it is simply moving about as a result of the output of the computer.
</p>

<p>
The combination reply and Searle's response raise some interesting problems with Searle's argument against strong AI. As previously implied, Searle shows that neither the computer inside the robot nor the robot shell understands on a semantic level. Searle shows that he can become the computer inside the system and that the computer does not understand. He also shows that the robot shell does not understand because it acts on the world as a result of the computer. However, he does not show that the system as a whole, the robot shell and the computer together, fail to understand on a semantic level. With the system's ability to interact with the world and behave in such a way that observers cannot distinguish its behavior from that of a human, there is no objective way to prove that the system does not understand on a this level without actually being the system. For this reason, Searle's argument against strong AI falls apart.
</p>

<p>
In conclusion, Searle's argument fails to defeat the claims of strong AI, but he does show something about the Turing Test. As previously noted, Searle's argument implies that the Turing Test can be passed without the ability to understand on a semantic level. A modification to the Turing test can then be proposed to address this issue. Instead of interacting via writing, the system would be given a way to show its ability to understand on a semantic level. This could be accomplished, as suggested in the robot reply, with a robot. If the behavior of the robotic system as it interacted with the world could not be distinguished from the behavior of a human, we would have to say that the system is able to understand on a semantic level. As previously discussed, there would be no way to prove otherwise without actually being the robot.
</p>    